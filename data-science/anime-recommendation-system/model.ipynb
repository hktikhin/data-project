{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45d121cd-6b36-4506-bdac-1e09a189befd",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to \n",
    "- Create a data pipline using dgl \n",
    "- Train a gnn model for recommendation system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "039b88e6-2411-4ff2-9c9e-79ed7b6357f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install dgl-cu116 dglgo -f https://data.dgl.ai/wheels/repo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a864131-aebf-4e76-b68a-0f0505c265de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl \n",
    "import os\n",
    "import torch\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import logging \n",
    "\n",
    "from typing import Iterator \n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from dgl import save_graphs, load_graphs\n",
    "from dgl.data import DGLDataset\n",
    "from dgl.data.utils import makedirs, save_info, load_info\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c82e9ab0-cc95-4892-85be-3e784a4a0559",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename='model_no_feat.log', \n",
    "    filemode='a',\n",
    "    force = True,\n",
    "    format='%(asctime)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S',\n",
    "    level=logging.INFO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3f0d93e-209d-47a5-b4fe-50cd424ba84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfromation function \n",
    "\n",
    "def tranform_duration(data: pd.DataFrame)->pd.DataFrame:\n",
    "    # typecasting duration from str to int\n",
    "    result = data.copy(deep=True)\n",
    "    tmp = result.Duration.dropna().str.extract(r\"((?P<hr>\\d*) hr. )?(?P<min>\\d*) min.\", expand=True)   \n",
    "    result.loc[result.Duration.notna(), \"Duration\"] = (tmp[\"hr\"].astype(float).fillna(0)+tmp[\"min\"].astype(float).fillna(0))\n",
    "    return result\n",
    "\n",
    "def tranform_aired(data: pd.DataFrame)->pd.DataFrame:\n",
    "    # typecasting air from str to int\n",
    "    # add a feature called year \n",
    "    result = data.copy(deep=True)\n",
    "    result[\"year\"] = result.Aired.str.extract(r\"(\\d{4})\").astype(float)\n",
    "    return result\n",
    "\n",
    "def create_genres_dummy(data: pd.DataFrame)->pd.DataFrame:\n",
    "    result = data.copy(deep=True)\n",
    "    tmp = result.Genres.dropna().apply(\n",
    "        lambda x: x.split(\", \") if isinstance(x, str) else x\n",
    "    ).tolist()\n",
    "    all_genres = Counter()\n",
    "    for lst in tmp:\n",
    "        all_genres.update(Counter(lst))\n",
    "    genre2idx = {g:idx for idx, g in enumerate(all_genres.keys())}\n",
    "    dummy_matrix = np.zeros((len(result),len(genre2idx)), dtype=int)\n",
    "    for idx, genres_lst in zip(result[result.Genres.notna()].index, tmp):\n",
    "        for genre in genres_lst:\n",
    "            dummy_matrix[idx, genre2idx[genre]] = 1\n",
    "    result[[\"genre_\"+g for g in genre2idx]] = dummy_matrix\n",
    "    return result\n",
    "\n",
    "def create_dummy(data: pd.DataFrame)->pd.DataFrame:\n",
    "    result = data.copy(deep=True)\n",
    "    tmp = []\n",
    "    use_col = ['Type', 'Source', 'Rating']\n",
    "    for col in use_col:\n",
    "        tmp.append(pd.get_dummies(result[col], prefix=col))\n",
    "    result = pd.concat([result]+tmp, axis = 1)\n",
    "    return result \n",
    "\n",
    "def fill_numeric_missing(data: pd.DataFrame)->pd.DataFrame:\n",
    "    result = data.copy(deep=True)\n",
    "    for col in result.columns:\n",
    "        if result[col].dtypes == \"float\":\n",
    "            result[col] = result[col].fillna(np.median(result[col].dropna()))\n",
    "    return result \n",
    "\n",
    "def remove_irrelevant_feature(data: pd.DataFrame)->pd.DataFrame:\n",
    "    # drop all categorical feature from result dataframe \n",
    "    result = data.copy(deep=True)\n",
    "    for col in result.columns:\n",
    "        if result[col].dtypes == \"O\":\n",
    "            del result[col]\n",
    "    return result  \n",
    "\n",
    "def normalize_feature(data: pd.DataFrame)->pd.DataFrame:\n",
    "    result = data.copy(deep=True)\n",
    "    # Apply min-max normlaization to the feature \n",
    "    scaler = MinMaxScaler()\n",
    "    result[result.columns[1:]] = scaler.fit_transform(result.iloc[:, 1:].values)\n",
    "    return result \n",
    "\n",
    "def filter_low_rating(data: pd.DataFrame)->pd.DataFrame:\n",
    "    result = data.copy(deep=True)\n",
    "    return result.loc[result.rating>=9, [\"user_id\", \"anime_id\"]]\n",
    "\n",
    "def filter_non_exist_anime(data: pd.DataFrame, anime_id: pd.Series)->pd.DataFrame:\n",
    "    result = data.copy(deep=True)\n",
    "    return result[result.anime_id.isin(anime_id)]\n",
    "\n",
    "def create_id_mapper(data: pd.DataFrame)->tuple[dict]:\n",
    "    tmp = data.copy(deep=True)\n",
    "    user_id = sorted(tmp.user_id.unique())\n",
    "    anime_id = sorted(tmp.anime_id.unique())\n",
    "    return {old_idx: new_idx for new_idx, old_idx in enumerate(user_id)}, {old_idx: new_idx for new_idx, old_idx in enumerate(anime_id)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea719f8f-35d6-451f-81c0-e4bcca31eced",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimeDataset(DGLDataset):\n",
    "    def __init__(self,\n",
    "                save_dir=None,\n",
    "                force_reload=False,\n",
    "                verbose=False):\n",
    "        super().__init__(name='anime_dataset',                                    \n",
    "                        save_dir=save_dir,\n",
    "                        force_reload=force_reload,\n",
    "                        verbose=verbose)\n",
    "        \n",
    "    def process(self):\n",
    "        anime_data = pd.read_csv(\"./data/anime.csv\", na_values = \"Unknown\")\n",
    "        rating_data = pd.read_csv(\"./data/rating_complete.csv.zip\")\n",
    "        # Tranfrom the anime dataframe and rating dataser\n",
    "        anime_data = (anime_data.pipe(tranform_duration)\\\n",
    "                .pipe(tranform_aired)\\\n",
    "                .pipe(fill_numeric_missing)\\\n",
    "                .pipe(tranform_aired)\\\n",
    "                .pipe(create_genres_dummy)\\\n",
    "                .pipe(create_dummy)\\\n",
    "                .pipe(remove_irrelevant_feature)\\\n",
    "                .pipe(normalize_feature)\n",
    "        )\n",
    "        anime_data = anime_data.dropna()\n",
    "        rating_data = (rating_data.pipe(filter_low_rating)\\\n",
    "            .pipe(filter_non_exist_anime, anime_id = anime_data.MAL_ID)\\\n",
    "        )\n",
    "        rating_data = rating_data.sample(frac=1, random_state=20221104)\n",
    "        \n",
    "        user_id_mapper, anime_id_mapper = create_id_mapper(rating_data)\n",
    "        torch.save(anime_id_mapper, \"data/anime_id_mapper.pt\")\n",
    "        # filter anime does have any rating \n",
    "        anime_data = anime_data[anime_data.MAL_ID.isin(anime_id_mapper)].iloc[:, 1:]\n",
    "        anime_features = torch.from_numpy(anime_data.to_numpy())\n",
    "        edges_src = torch.from_numpy(rating_data['user_id'].apply(lambda idx: user_id_mapper[idx]).to_numpy())\n",
    "        edges_dst = torch.from_numpy(rating_data['anime_id'].apply(lambda idx: anime_id_mapper[idx]).to_numpy())\n",
    "        num_nodes_dict = {'anime': len(anime_id_mapper), 'user': len(user_id_mapper)}\n",
    "        \n",
    "        self.graph = dgl.heterograph({\n",
    "            ('user', 'like', 'anime'): (edges_src, edges_dst),\n",
    "            ('anime', 'rev_like', 'user'): (edges_dst, edges_src)\n",
    "        }, num_nodes_dict = num_nodes_dict, idtype=torch.int32)\n",
    "        self.graph.nodes['anime'].data['feat'] = anime_features\n",
    "\n",
    "        n_edges = self.graph.number_of_edges(etype=('user', 'like', 'anime'))\n",
    "        n_train_message = int(n_edges * 0.5)\n",
    "        n_train_supervise = int(n_edges * 0.3)\n",
    "        n_val = int(n_edges * 0.1)\n",
    "        \n",
    "        train_message_mask = torch.zeros(n_edges, dtype=torch.bool)\n",
    "        train_supervise_mask = torch.zeros(n_edges, dtype=torch.bool)\n",
    "        val_mask = torch.zeros(n_edges, dtype=torch.bool)\n",
    "        test_mask = torch.zeros(n_edges, dtype=torch.bool)\n",
    "        \n",
    "        train_message_mask[: n_train_message] = True\n",
    "        train_supervise_mask[n_train_message: n_train_message + n_train_supervise] = True\n",
    "        val_mask[n_train_message + n_train_supervise: n_train_message + n_train_supervise + n_val] = True\n",
    "        test_mask[n_train_message + n_train_supervise + n_val:] = True\n",
    "        \n",
    "        self.graph.edges['like'].data['train_message_mask'] = train_message_mask\n",
    "        self.graph.edges['like'].data['train_supervise_mask'] = train_supervise_mask\n",
    "        self.graph.edges['like'].data['val_mask'] = val_mask\n",
    "        self.graph.edges['like'].data['test_mask'] = test_mask\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        return self.graph\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def save(self):\n",
    "        # save graphs\n",
    "        graph_path = os.path.join(self.save_dir, 'anime_dgl_graph.bin')\n",
    "        save_graphs(graph_path, self.graph)\n",
    "\n",
    "    def load(self):\n",
    "        # load processed data from directory `self.save_path`\n",
    "        graph_path = os.path.join(self.save_dir, 'anime_dgl_graph.bin')\n",
    "        self.graph = load_graphs(graph_path)[0][0]\n",
    "\n",
    "    def has_cache(self):\n",
    "        # check whether there are processed data in `self.save_path`\n",
    "        graph_path = os.path.join(self.save_dir, 'anime_dgl_graph.bin')\n",
    "        return os.path.exists(graph_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "348d6dd7-d0dc-4889-b86c-9625cdaee728",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = AnimeDataset(save_dir=\"./data\")\n",
    "graph = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "494b701c-cabe-4503-b004-ac9d4b335eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'anime': 16343, 'user': 306492},\n",
       "      num_edges={('anime', 'rev_like', 'user'): 16489589, ('user', 'like', 'anime'): 16489589},\n",
       "      metagraph=[('anime', 'user', 'rev_like'), ('user', 'anime', 'like')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee43861-1195-4f94-921d-87e6cbb9acc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23385057-84ff-4e4f-a02e-82493c2bd0bf",
   "metadata": {},
   "source": [
    "#### Build the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6771612f-cbd5-40ac-a449-010ba7537dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eids = np.arange(graph['like'].num_edges())\n",
    "train_edge_size = graph.edges['like'].data['train_message_mask'].sum() + graph.edges['like'].data['train_supervise_mask'].sum()\n",
    "val_edge_size = train_edge_size + graph.edges['like'].data['val_mask'].sum()\n",
    "train_g = dgl.remove_edges(graph, eids[train_edge_size:], etype=\"like\")\n",
    "train_g = dgl.remove_edges(train_g, eids[train_edge_size:], etype=\"rev_like\")\n",
    "valid_g = dgl.remove_edges(graph, eids[val_edge_size:], etype=\"like\")\n",
    "valid_g = dgl.remove_edges(valid_g, eids[val_edge_size:], etype=\"rev_like\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "165f65bb-710c-4735-8b29-ee684a2f6579",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# hyperparameter \n",
    "batch_size = 4096 #1024\n",
    "hidden_dims = 64\n",
    "in_dims = graph.nodes['anime'].data['feat'].size(1)\n",
    "out_dims = 64\n",
    "# number of rgcn layers \n",
    "num_layer = 2\n",
    "num_neg_sample = 5\n",
    "# Max recommendation items to consider \n",
    "k = 10\n",
    "n_epochs = 10\n",
    "weight_decay = 5e-4\n",
    "lr = 1e-3\n",
    "etypes = graph.etypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33629625-1cef-4292-9b28-2de91bd84951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.0, 33.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average indegree for anime\n",
    "average_user_count = graph.in_degrees(etype=\"like\").float().median().item()\n",
    "# average outdegree for user\n",
    "average_anime_count = graph.out_degrees(etype=\"like\").float().median().item()\n",
    "average_user_count, average_anime_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f66e699-efc6-43dc-af4d-6b0decfdaab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader_with_sampling(graph, mask, sampler, device, batch_size=32, shuffle=False):\n",
    "    idx = torch.nonzero(mask, as_tuple=False).int().squeeze()\n",
    "    loader = dgl.dataloading.DataLoader(\n",
    "        graph, {\"like\": idx}, sampler,\n",
    "        batch_size=batch_size,\n",
    "        device=device,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=False,\n",
    "        use_uva=True\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "def generate_history_interaction(u, v):\n",
    "    result = defaultdict(list)\n",
    "    for src, dst in zip(u, v):\n",
    "        result[src.item()].append(dst.item())\n",
    "    return result \n",
    "\n",
    "def generate_user_batch(g, batch_size) -> Iterator:\n",
    "    user_ids = torch.arange(g.number_of_nodes(\"user\")).type(torch.int32)\n",
    "    num_batch = g.number_of_nodes(\"user\")//batch_size+1\n",
    "    for i in range(1, num_batch+1):\n",
    "        if i == num_batch:\n",
    "            batch_user_id = user_ids[batch_size*(i-1):]\n",
    "            yield batch_user_id\n",
    "            break\n",
    "        batch_user_id = user_ids[batch_size*(i-1): batch_size*i]\n",
    "        yield batch_user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5aaa7fb-619a-4302-ab0f-161dc72c3e67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StochasticMultipleLayerRGCN(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feat, out_feat, rel_names, n_layers):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        # hidden layers\n",
    "        for i in range(n_layers - 1):\n",
    "            if i == 0:\n",
    "                # input layer\n",
    "                self.layers.append(dglnn.HeteroGraphConv({\n",
    "                        rel : dglnn.SAGEConv(in_feats, hidden_feat, aggregator_type='mean')\n",
    "                        for rel in rel_names\n",
    "                    })\n",
    "                )\n",
    "            else:\n",
    "                self.layers.append(dglnn.HeteroGraphConv({\n",
    "                        rel : dglnn.SAGEConv(hidden_feat, hidden_feat, aggregator_type='mean')\n",
    "                        for rel in rel_names\n",
    "                    })\n",
    "                )\n",
    "\n",
    "        # output layer\n",
    "        self.layers.append(dglnn.HeteroGraphConv({\n",
    "                rel : dglnn.SAGEConv(hidden_feat, out_feat, aggregator_type='mean')\n",
    "                for rel in rel_names\n",
    "            })\n",
    "        )\n",
    "        \n",
    "    def forward(self, blocks, x):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(blocks[i], x)\n",
    "        return x\n",
    "    \n",
    "class ScorePredictor(nn.Module):\n",
    "    def forward(self, edge_subgraph, x):\n",
    "        with edge_subgraph.local_scope():\n",
    "            edge_subgraph.ndata['x'] = x\n",
    "            for etype in edge_subgraph.canonical_etypes:\n",
    "                edge_subgraph.apply_edges(\n",
    "                    dgl.function.u_dot_v('x', 'x', 'score'), etype=etype)\n",
    "            return edge_subgraph.edata['score']\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, etypes, num_layer=2, use_feat=False):\n",
    "        super().__init__()\n",
    "        self.in_dims = in_features\n",
    "        self.hidden_dims = hidden_features\n",
    "        self.out_dims = out_features\n",
    "        self.use_feat = use_feat\n",
    "        self.num_layer = num_layer\n",
    "        # Since the dataset does not come with rich features, we also learn two\n",
    "        # embedding matrices for users and movies:\n",
    "        if use_feat:\n",
    "            self.anime_lin = torch.nn.Linear(in_features, hidden_features)\n",
    "        self.anime_emb = torch.nn.Embedding(graph.num_nodes(\"anime\"), hidden_features)\n",
    "        self.user_emb = torch.nn.Embedding(graph.num_nodes(\"user\"), hidden_features)\n",
    "        self.rgcn = StochasticMultipleLayerRGCN(\n",
    "            hidden_features, hidden_features, out_features, etypes, num_layer\n",
    "        )\n",
    "        self.pred = ScorePredictor()\n",
    "\n",
    "    def forward(self, input_nodes, positive_graph, negative_graph, blocks, x):\n",
    "        x_anime = self.anime_lin(x[\"anime\"])+self.anime_emb(input_nodes[\"anime\"]) if self.use_feat else self.anime_emb(input_nodes[\"anime\"]) \n",
    "        x_dict = {\n",
    "            \"user\": self.user_emb(input_nodes[\"user\"]),\n",
    "            \"anime\": x_anime,\n",
    "        }\n",
    "            \n",
    "        x = self.rgcn(blocks, x_dict)\n",
    "        pos_score = self.pred(positive_graph, x)\n",
    "        neg_score = self.pred(negative_graph, x)\n",
    "        return pos_score, neg_score\n",
    "    \n",
    "    def inference(self, g, anime_feat, batch_size, device):\n",
    "        \"\"\"\n",
    "        Perform offline inference \n",
    "        Params\n",
    "         - g: The dgl graph without test edge \n",
    "         - x_anime: feature tensor for anime\n",
    "        \n",
    "        Return\n",
    "         - Final embedding for all node \n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        # input embedding/ feature      \n",
    "        x_anime = self.anime_lin(anime_feat.float().to(device))+self.anime_emb.weight if self.use_feat else self.anime_emb.weight \n",
    "        x = {\n",
    "            \"user\": self.user_emb.weight,\n",
    "            \"anime\": x_anime\n",
    "        }\n",
    "        \n",
    "        for l, layer in enumerate(self.rgcn.layers):\n",
    "            # initialize the next layer embedding(output)\n",
    "            y = {\n",
    "                k: torch.zeros(\n",
    "                    g.number_of_nodes(k),\n",
    "                    self.hidden_dims if l != 1 else self.out_dims,\n",
    "                )\n",
    "                for k in g.ntypes\n",
    "            }\n",
    "            sampler = dgl.dataloading.MultiLayerFullNeighborSampler(1)\n",
    "\n",
    "            # sample all node in graph \n",
    "            dataloader = dgl.dataloading.DataLoader(\n",
    "                g,\n",
    "                {k: torch.arange(g.number_of_nodes(k), dtype=torch.int32) for k in g.ntypes},\n",
    "                sampler,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                drop_last=False,\n",
    "                use_uva=True,\n",
    "                device=device\n",
    "            )\n",
    "            \n",
    "            for input_nodes, output_nodes, blocks in tqdm.tqdm(dataloader):\n",
    "                block = blocks[0].to(device)\n",
    "                input_nodes = {k: v.long() for k, v in input_nodes.items()}\n",
    "                output_nodes = {k: v.long() for k, v in output_nodes.items()}\n",
    "                # Select subset of x\n",
    "                h = {\n",
    "                    k: x[k][input_nodes[k]].to(device)\n",
    "                    for k in input_nodes.keys()\n",
    "                }\n",
    "                h = layer(block, h)\n",
    "                # update y\n",
    "                for k in output_nodes.keys():\n",
    "                    y[k][output_nodes[k]] = h[k].cpu()\n",
    "            # update x \n",
    "            x = y\n",
    "        # Save the computation result \n",
    "        #torch.save(y, \"data/final_embedding_dict.pt\")\n",
    "        return y \n",
    "    \n",
    "    def recommend(self, y, src_index = None, hist_dict = None, k = 1):\n",
    "        \"\"\"\n",
    "        Generate top k recommendation for node with 'src_index'\n",
    "        Params:\n",
    "        - y: the final embedding for the user and anime, which is a dict of tensor \n",
    "        - src_index: tensor index for the user who we want to generate anime recommendation\n",
    "        - hist_dict: contain the history interaction for anime and user. use it to filter the recommendation set,\n",
    "        must contain same src_index\n",
    "        Return:\n",
    "        - dict of indices for the recommended anime \n",
    "        \"\"\"\n",
    "        #y = torch.load(\"data/final_embedding_dict.pt\")\n",
    "        user_src = y[\"user\"]\n",
    "        anime_dst = y[\"anime\"]\n",
    "        top_index = defaultdict(list)\n",
    "        \n",
    "        if src_index is not None:\n",
    "            user_src = user_src[src_index]\n",
    "\n",
    "        pred = user_src @ anime_dst.t()\n",
    "        # IndexError: index 1024 is out of bounds for dimension 0 with size 1024\n",
    "        #print(pred)\n",
    "        #print(pred.size())\n",
    "        # IndexError: index -1024 is out of bounds for dimension 0 with size 316\n",
    "        for new_uid, uid in enumerate(hist_dict):\n",
    "            # the uid 1024 is exceed the pred index \n",
    "            # because when second batch is coming, the index is reset for pred(don't use global index) \n",
    "            # we can solve it by tracking the # of batch of batch size\n",
    "            # another way is to just use the size of hist_dict to construct the index\n",
    "            _, indices = pred[new_uid].sort(descending=True, dim=-1)\n",
    "            mask = torch.isin(indices, torch.tensor(hist_dict[uid]), invert=True)\n",
    "            top_index[uid] = indices[mask][:k].tolist()\n",
    "            \n",
    "        return top_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea054b66-7134-4f31-b1cf-944f97e033bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and evaluation metrics \n",
    "def compute_loss(pos_score, neg_score):\n",
    "    # Margin loss\n",
    "    n_edges = pos_score.shape[0]\n",
    "    return (1 - pos_score + neg_score.view(n_edges, -1)).clamp(min=0).mean()\n",
    "\n",
    "def mrr(pos_score, neg_score):\n",
    "    \"\"\"\n",
    "    Calculates mean reciprocal rank (MRR) for given positive sample score and negative sample score\n",
    "    Used only in validation context\n",
    "    :param pos_score: BX1 tensor with the logit score\n",
    "    :param neg_score: (B*k)X1 tensor with the logit score\n",
    "    :return: Mean reciprocal rank score\n",
    "    \"\"\"\n",
    "    n_edges = pos_score.shape[0]\n",
    "    neg_score = neg_score.view(n_edges, -1)\n",
    "    # indice for the sorted score\n",
    "    indices = torch.cat([pos_score, neg_score], dim=1).argsort(dim=1, descending=True)\n",
    "    return (1.0 / (indices == 0).nonzero()[:, 1].float().add(1.0)).sum().item()\n",
    "\n",
    "def hit_at_k(top_index, hist_watch_dict, k):\n",
    "    \"\"\"Calculates number of hits@k: \n",
    "    Formula: # of user who find the relevant item in top k set/ # of user \n",
    "    :param top_index: dict of recommended anime per user \n",
    "    :param hist_watch_dict: dict of user watching history in the test set\n",
    "\n",
    "    :param k: number of top K results to be considered as hits\n",
    "    :return: Hits@K score\n",
    "    \"\"\"\n",
    "    # AssertionError:\n",
    "    # different len for test user and recommendation user\n",
    "    # assert len(top_index) == len(hist_watch_dict)\n",
    "    num_user = len(hist_watch_dict)\n",
    "    total_hits = 0\n",
    "    for uid in hist_watch_dict:\n",
    "        s1 = set(top_index[uid][:k])\n",
    "        s2 = set(hist_watch_dict[uid])\n",
    "        # find the comment element between two set\n",
    "        s3 = s1.intersection(s2)\n",
    "        if len(s3)>0: total_hits +=1 \n",
    "    return total_hits/num_user\n",
    "\n",
    "def precision_at_k(top_index, hist_watch_dict, k):\n",
    "    \"\"\"Calculates number of precision@k: \n",
    "    Formula: # of recommended items that is relevant(TP) / # of recommended items(TP+FP) \n",
    "    :param top_index: dict of recommended anime per user \n",
    "    :param hist_watch_dict: dict of user watching history in the test set\n",
    "\n",
    "    :param k: number of top K results to be recommended \n",
    "    :return: Precision@K score\n",
    "    \"\"\"\n",
    "    num_user = len(hist_watch_dict)\n",
    "    total_tp = 0\n",
    "    for uid in hist_watch_dict:\n",
    "        s1 = set(top_index[uid][:k])\n",
    "        s2 = set(hist_watch_dict[uid])\n",
    "        # find the comment element between two set\n",
    "        s3 = s1.intersection(s2)\n",
    "        total_tp += len(s3)\n",
    "    return total_tp/(num_user*k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "585a96a4-89c0-4560-ae90-a9464f20088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainning loop\n",
    "def Train(model, train_dataloader, val_dataloader, optimizer, n_epochs, best_model_path):\n",
    "    model = model.to(device)\n",
    "    best_mrr = best_epoch =  0\n",
    "    auc_lst = []\n",
    "    mrr_lst = []\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        model.train()\n",
    "        total_loss = total_examples = 0\n",
    "        for input_nodes, positive_graph, negative_graph, blocks in tqdm.tqdm(train_loader):\n",
    "            input_features = {k: v.float() for k, v in blocks[0].srcdata['feat'].items()}\n",
    "            pos_score_dict, neg_score_dict = model(input_nodes, positive_graph, negative_graph, blocks, input_features)\n",
    "            \n",
    "            pos_score = pos_score_dict[\"user\", \"like\", \"anime\"]\n",
    "            neg_score = neg_score_dict[\"user\", \"like\", \"anime\"]\n",
    "            loss = compute_loss(pos_score, neg_score)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            total_loss += float(loss) * pos_score.shape[0]\n",
    "            total_examples += pos_score.shape[0]\n",
    "        auc, mrr = Evaluate(model, val_dataloader)\n",
    "        auc_lst.append(auc)\n",
    "        mrr_lst.append(mrr)\n",
    "        if mrr > best_mrr:\n",
    "            best_mrr = mrr\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "        logging.info(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}, AUC: {auc:.4f}, MRR: {mrr:.4f}\")\n",
    "    logging.info(f\"The best epoch is {best_epoch} with mrr score {best_mrr:.4f}\")\n",
    "    return auc_lst, mrr_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "318169a2-dba6-4aab-9d27-7efa14c21e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate(model, eval_dataloader):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = []\n",
    "        ground_truths = []\n",
    "        mrr_sum = 0\n",
    "        num_pos_edge = 0\n",
    "        for input_nodes, positive_graph, negative_graph, blocks in tqdm.tqdm(eval_dataloader):\n",
    "            input_features = {k: v.float() for k, v in blocks[0].srcdata['feat'].items()}\n",
    "            pos_score_dict, neg_score_dict = model(input_nodes, positive_graph, negative_graph, blocks, input_features)\n",
    "\n",
    "            pos_score = pos_score_dict[\"user\", \"like\", \"anime\"]\n",
    "            neg_score = neg_score_dict[\"user\", \"like\", \"anime\"]\n",
    "            \n",
    "            pred = torch.cat([pos_score, neg_score])\n",
    "            label = torch.cat([torch.ones_like(pos_score), torch.zeros_like(neg_score)])\n",
    "            mrr_sum += mrr(pos_score, neg_score)\n",
    "            num_pos_edge += len(pos_score)\n",
    "            preds.append(pred)\n",
    "            ground_truths.append(label)\n",
    "        preds = torch.cat(preds, dim=0).cpu().numpy()\n",
    "        ground_truths = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
    "        auc = roc_auc_score(ground_truths, preds)\n",
    "    return auc, mrr_sum/ num_pos_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92ab3d09-5b4e-4d75-9daf-fe6f490655fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test(model, max_k, val_g, full_g, batch_size, device, path):\n",
    "    \"\"\"\n",
    "    Get the final embedding with the validation subgraph \n",
    "    and generate recommendation then evaluate the performance with hit rate \n",
    "    Params:\n",
    "    - model: pytorch model\n",
    "    - max_k: max # of recommendation results \n",
    "    - val_g: subgraph \n",
    "    - full_g: fullgraph\n",
    "    - path: where to save the recommendation list for each user \n",
    "    return:\n",
    "    - dict of user id and topk recommendation items \n",
    "    - test hit@k dict k={1, 2, ..., max_k}\n",
    "    \"\"\"\n",
    "    test_hr_dict={}\n",
    "    test_precision_dict={}\n",
    "    model = model.to(device)\n",
    "    # Generate final embedding and save the result\n",
    "    y = model.inference(val_g, graph.ndata[\"feat\"][\"anime\"], batch_size*3, device)\n",
    "    results = defaultdict(list)\n",
    "    user_batch = generate_user_batch(full_g, batch_size=batch_size*3)\n",
    "    for uids in tqdm.tqdm(user_batch):\n",
    "        # DGLError: Expect argument \"u\" to have data type torch.int32. But got torch.int64.\n",
    "        u, v = val_g.out_edges(uids, etype='like')\n",
    "        hist_interact_dict = generate_history_interaction(u, v)\n",
    "        #print(uids)\n",
    "        topk_rec = model.recommend(y, src_index = uids.long(), k=max_k, hist_dict = hist_interact_dict)\n",
    "        results.update(topk_rec)\n",
    "    # Save the result recommendation\n",
    "    torch.save(results, path)\n",
    "    # get the testing edge \n",
    "    test_eid = torch.nonzero(full_g.edges['like'].data['test_mask'], as_tuple=False).int().squeeze()\n",
    "    test_interact_dict = generate_history_interaction(*full_g.find_edges(test_eid, etype=\"like\"))\n",
    "    # evaluate the result\n",
    "    for k in range(1, max_k+1):\n",
    "        hr = hit_at_k(results, test_interact_dict, k)\n",
    "        precision = precision_at_k(results, test_interact_dict, k)\n",
    "        logging.info(f\"hit@{k}: {hr:.4f}\")\n",
    "        logging.info(f\"precision@{k}: {precision:.4f}\")\n",
    "        test_hr_dict[k] = hr\n",
    "        test_precision_dict[k] = precision\n",
    "        \n",
    "    return results, test_hr_dict, test_precision_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "971a2e5e-80a8-4f30-8462-7c7a60ab9c80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define data loader \n",
    "train_sampler = dgl.dataloading.NeighborSampler(\n",
    "    [{\n",
    "        (\"user\", \"like\", \"anime\"): average_user_count,\n",
    "        (\"anime\", \"rev_like\", \"user\"): average_anime_count\n",
    "    }]*num_layer)\n",
    "train_sampler = dgl.dataloading.as_edge_prediction_sampler(\n",
    "    train_sampler, \n",
    "    negative_sampler=dgl.dataloading.negative_sampler.Uniform(num_neg_sample),\n",
    "    exclude='reverse_types',\n",
    "    reverse_etypes={'like': 'rev_like', 'rev_like': 'like'}\n",
    ")\n",
    "train_supervise_mask = graph.edges['like'].data['train_supervise_mask']\n",
    "train_loader = get_dataloader_with_sampling(\n",
    "    graph = train_g,\n",
    "    mask = train_supervise_mask,\n",
    "    sampler = train_sampler,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "629e3990-9b78-42ea-b038-85ac440c7e99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_sampler = dgl.dataloading.NeighborSampler(\n",
    "    [{\n",
    "        (\"user\", \"like\", \"anime\"): average_user_count,\n",
    "        (\"anime\", \"rev_like\", \"user\"): average_anime_count\n",
    "    }]*num_layer)\n",
    "val_sampler = dgl.dataloading.as_edge_prediction_sampler(\n",
    "    val_sampler, \n",
    "    negative_sampler=dgl.dataloading.negative_sampler.Uniform(num_neg_sample),\n",
    "    exclude='reverse_types',\n",
    "    reverse_etypes={'like': 'rev_like', 'rev_like': 'like'}\n",
    ")\n",
    "val_mask = graph.edges['like'].data['val_mask']\n",
    "val_loader = get_dataloader_with_sampling(\n",
    "    graph = valid_g,\n",
    "    mask = val_mask,\n",
    "    sampler = val_sampler,\n",
    "    batch_size = batch_size*3,\n",
    "    shuffle = False,\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666b37ea-3479-4516-b033-e190da919b75",
   "metadata": {},
   "source": [
    "#### Result without feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dd6708f-e950-4bce-94aa-1bc7d0d3aa60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1208/1208 [01:07<00:00, 17.96it/s]\n",
      "100%|██████████| 135/135 [00:06<00:00, 21.88it/s]\n",
      "100%|██████████| 1208/1208 [01:06<00:00, 18.22it/s]\n",
      "100%|██████████| 135/135 [00:06<00:00, 21.79it/s]\n",
      "100%|██████████| 1208/1208 [01:07<00:00, 17.97it/s]\n",
      "100%|██████████| 135/135 [00:06<00:00, 21.80it/s]\n",
      "100%|██████████| 1208/1208 [01:06<00:00, 18.13it/s]\n",
      "100%|██████████| 135/135 [00:06<00:00, 21.85it/s]\n",
      "100%|██████████| 1208/1208 [01:07<00:00, 17.91it/s]\n",
      "100%|██████████| 135/135 [00:06<00:00, 21.13it/s]\n",
      "100%|██████████| 1208/1208 [01:06<00:00, 18.06it/s]\n",
      "100%|██████████| 135/135 [00:06<00:00, 21.65it/s]\n",
      "100%|██████████| 1208/1208 [01:06<00:00, 18.09it/s]\n",
      "100%|██████████| 135/135 [00:06<00:00, 21.60it/s]\n",
      "100%|██████████| 1208/1208 [01:06<00:00, 18.13it/s]\n",
      "100%|██████████| 135/135 [00:06<00:00, 21.65it/s]\n",
      "100%|██████████| 1208/1208 [01:07<00:00, 17.94it/s]\n",
      "100%|██████████| 135/135 [00:06<00:00, 21.73it/s]\n",
      "100%|██████████| 1208/1208 [01:06<00:00, 18.17it/s]\n",
      "100%|██████████| 135/135 [00:06<00:00, 21.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# Specify a path\n",
    "PATH = \"data/state_dict_model.pt\"\n",
    "# Run trainning and save the model with highest auc\n",
    "model = Model(in_dims, hidden_dims, out_dims, etypes, num_layer)\n",
    "model = model.to(device)\n",
    "model = model.float()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "auc_lst, mrr_lst = Train(model, train_loader, val_loader, opt, n_epochs, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "379b2e87-d02b-4417-8994-b44b4be8110c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 85.76it/s]\n",
      "100%|██████████| 27/27 [00:01<00:00, 21.13it/s]\n",
      "25it [17:29, 41.98s/it]\n"
     ]
    }
   ],
   "source": [
    "# Specify a path\n",
    "PATH = \"data/state_dict_model.pt\"\n",
    "REC_PATH = \"data/topk_recommendation.pt\"\n",
    "# Load the model and run testing \n",
    "model = Model(in_dims, hidden_dims, out_dims, etypes, num_layer)\n",
    "model.load_state_dict(torch.load(PATH, map_location=device))\n",
    "model.eval()\n",
    "rec_result, hr_dict, precision_dict = Test(model, k, valid_g, graph, batch_size, device, REC_PATH)\n",
    "# test: running time 24 mins. 300it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ea948b-1cfa-4db3-ba14-b5d12044b6c7",
   "metadata": {},
   "source": [
    "#### Result with feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2c493db-fefc-4826-a9b4-3661942f7582",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename='model_with_feat.log', \n",
    "    filemode='a',\n",
    "    force = True,\n",
    "    format='%(asctime)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S',\n",
    "    level=logging.INFO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d55a5c5-e125-4f58-bf8e-83309e8a4732",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1208/1208 [01:07<00:00, 17.99it/s]\n",
      "100%|██████████| 135/135 [00:06<00:00, 21.79it/s]\n",
      "100%|██████████| 1208/1208 [01:07<00:00, 17.94it/s]\n",
      "100%|██████████| 135/135 [00:06<00:00, 21.59it/s]\n",
      "100%|██████████| 1208/1208 [01:07<00:00, 18.01it/s]\n",
      "100%|██████████| 135/135 [00:06<00:00, 21.83it/s]\n",
      "100%|██████████| 1208/1208 [01:07<00:00, 17.93it/s]\n",
      "100%|██████████| 135/135 [00:06<00:00, 21.76it/s]\n",
      "100%|██████████| 1208/1208 [01:07<00:00, 17.90it/s]\n",
      "100%|██████████| 135/135 [00:06<00:00, 21.70it/s]\n",
      "100%|██████████| 1208/1208 [01:06<00:00, 18.04it/s]\n",
      "100%|██████████| 135/135 [00:06<00:00, 21.73it/s]\n",
      "100%|██████████| 1208/1208 [01:07<00:00, 17.78it/s]\n",
      "100%|██████████| 135/135 [00:06<00:00, 21.68it/s]\n",
      "100%|██████████| 1208/1208 [01:07<00:00, 17.94it/s]\n",
      "100%|██████████| 135/135 [00:06<00:00, 21.65it/s]\n",
      "100%|██████████| 1208/1208 [01:07<00:00, 17.86it/s]\n",
      "100%|██████████| 135/135 [00:06<00:00, 21.70it/s]\n",
      "100%|██████████| 1208/1208 [01:07<00:00, 17.97it/s]\n",
      "100%|██████████| 135/135 [00:06<00:00, 21.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# Specify a path\n",
    "PATH = \"data/state_dict_model_feat.pt\"\n",
    "# Run trainning and save the model with highest auc\n",
    "model = Model(in_dims, hidden_dims, out_dims, etypes, num_layer, use_feat = True)\n",
    "model = model.to(device)\n",
    "model = model.float()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "auc_lst1, mrr_lst1 = Train(model, train_loader, val_loader, opt, n_epochs, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ee3da30-7cb2-42ed-8263-16e2a9faba12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 92.65it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 32.47it/s]\n",
      "25it [17:23, 41.75s/it]\n"
     ]
    }
   ],
   "source": [
    "# Specify a path\n",
    "PATH = \"data/state_dict_model_feat.pt\"\n",
    "REC_PATH = \"data/topk_recommendation_feat.pt\"\n",
    "# Load the model and run testing \n",
    "model = Model(in_dims, hidden_dims, out_dims, etypes, num_layer, use_feat=True)\n",
    "model.load_state_dict(torch.load(PATH, map_location=device))\n",
    "model.eval()\n",
    "rec_result1, hr_dict1, precision_dict = Test(model, k, valid_g, graph, batch_size, device, REC_PATH)\n",
    "# test: running time 24 mins. 300it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da12ab9f-1dc4-4560-9816-769e1e8c5e03",
   "metadata": {},
   "source": [
    "Observation:\n",
    "- With feature the trainning score is better \n",
    "- However the testing score is lower (Overfitting), Not generalize to the test example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009eacc5-bc13-43ea-a910-8cc1703d4797",
   "metadata": {},
   "source": [
    "#### Random Walk Approch \n",
    "In the following section, I will try to explore using random walk sampling to make recommendation and answer the following questions\n",
    "- If we sample the random walk for each user without the test edge (only validation subgraph), what is the top 10 most visited anime?\n",
    "- What is the length of the random walk? Are there optimal number of length?\n",
    "- Should we include restart probability? Are there optimal number of it?\n",
    "- How can we evaluate the perfomance of the model and tune the parameter?\n",
    "- What should be the metapath from the user? user->anime->user->anime ....\n",
    "- What if we can find other attribute connect different anime together (leverage feature of the anine e.g. genre/ yr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c0d9eb3-4ba2-4acc-8cba-95e861018cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.sampling import random_walk\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99e9adf0-46db-496f-83ae-5d8c8090240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename='model_random_walk.log', \n",
    "    filemode='a',\n",
    "    force = True,\n",
    "    format='%(asctime)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S',\n",
    "    level=logging.INFO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "38d7a830-8de2-4f6a-b3ff-58e7231e413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_with_random_walk(g, num_random_walks: int = 1000, num_repeated: int = 2, restart_prob: float = .5, k: int = 10):\n",
    "    \n",
    "    seed = torch.arange(g.num_nodes(\"user\")).type(torch.int32)\n",
    "    tmp = []\n",
    "    for _ in tqdm.tqdm(range(num_random_walks)):\n",
    "        result = random_walk(g, seed.to(device), metapath=['like', 'rev_like'] * num_repeated,\n",
    "            restart_prob=torch.FloatTensor([0, restart_prob, 0, restart_prob]).to(device)\n",
    "        )\n",
    "        # result[0] return the path, result[1] return the type of node for that path\n",
    "        # 0-> anime, 1-> user\n",
    "        # -1 mean the trace is terminated \n",
    "        sample_anime = result[0][:, result[1] == 0]\n",
    "        tmp.append(sample_anime)\n",
    "    final_sample_anime = torch.concat(tmp, axis=1)\n",
    "    topk_visited_anime = {}\n",
    "    for i in tqdm.tqdm(range(g.num_nodes(\"user\"))):\n",
    "        c = Counter()\n",
    "        u, v = g.out_edges([i], etype='like')\n",
    "        c.update(final_sample_anime[i, :].tolist())\n",
    "        for dst in v.tolist():\n",
    "            del c[dst]\n",
    "        del c[-1]\n",
    "        topk_visited_anime[i] = [anime_idx for anime_idx,_ in c.most_common(k)]\n",
    "    return topk_visited_anime\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d037268-130c-48c3-bed0-fd6825547d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_random_walk(train_g, full_g, params: dict, k: int=10):\n",
    "    assert list(params.keys()) == ['num_repeated', 'restart_prob']\n",
    "    best_precision = 0 \n",
    "    best_params = {}\n",
    "    params_comb = product(params[\"num_repeated\"], params[\"restart_prob\"])\n",
    "    # get the validation edge \n",
    "    val_eid = torch.nonzero(full_g.edges['like'].data['val_mask'], as_tuple=False).int().squeeze()\n",
    "    val_interact_dict = generate_history_interaction(*full_g.find_edges(val_eid, etype=\"like\"))\n",
    "    for num_repeated, restart_prob in params_comb:\n",
    "        topk_visited_anime = recommend_with_random_walk(train_g, num_repeated = num_repeated, restart_prob = restart_prob)\n",
    "        # evaluate the result\n",
    "        hr = hit_at_k(topk_visited_anime, val_interact_dict, k)\n",
    "        precision = precision_at_k(topk_visited_anime, val_interact_dict, k)\n",
    "        logging.info(f\"({num_repeated}, {restart_prob}) :: hit@{k}: {hr:.4f}, precision@{k}: {precision:.4f}\")\n",
    "        if precision > best_precision:\n",
    "            best_precision = precision\n",
    "            best_params = {\"num_repeated\": num_repeated, \"restart_prob\": restart_prob}\n",
    "    logging.info(f\"The best params is {best_params} with precision {best_precision:.4f}\")\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afff322d-de24-4323-a800-b4453692802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_random_walk(val_g, full_g, params: dict, max_k: int=10):\n",
    "    assert list(params.keys()) == ['num_repeated', 'restart_prob']\n",
    "    test_hr_dict = {}\n",
    "    test_precision_dict = {}\n",
    "    # get the testing edge \n",
    "    test_eid = torch.nonzero(full_g.edges['like'].data['test_mask'], as_tuple=False).int().squeeze()\n",
    "    test_interact_dict = generate_history_interaction(*full_g.find_edges(test_eid, etype=\"like\"))\n",
    "    topk_visited_anime = recommend_with_random_walk(val_g, **params)\n",
    "    # evaluate the result\n",
    "    for k in range(1, max_k+1):\n",
    "        hr = hit_at_k(topk_visited_anime, test_interact_dict, k)\n",
    "        precision = precision_at_k(topk_visited_anime, test_interact_dict, k)\n",
    "        logging.info(f\"hit@{k}: {hr:.4f}\")\n",
    "        logging.info(f\"precision@{k}: {precision:.4f}\")\n",
    "        test_hr_dict[k] = hr\n",
    "        test_precision_dict[k] = precision\n",
    "        \n",
    "    return topk_visited_anime, test_hr_dict, test_precision_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f9dacd2-6b3b-43b0-979a-a9ccae03b17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_repeated = 1 is meaningless as it means recommend the previous watched anime \n",
    "params = {\n",
    "    \"num_repeated\" : [i for i in range(2, 5)],\n",
    "    \"restart_prob\" : [i/10 for i in range(0, 10, 2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0133e6f1-8462-41f3-8c7d-5a26d103df2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:31<00:00, 31.56it/s]\n",
      "100%|██████████| 306492/306492 [02:38<00:00, 1928.26it/s]\n",
      "100%|██████████| 1000/1000 [00:24<00:00, 41.08it/s]\n",
      "100%|██████████| 306492/306492 [02:36<00:00, 1962.15it/s]\n",
      "100%|██████████| 1000/1000 [00:21<00:00, 47.17it/s]\n",
      "100%|██████████| 306492/306492 [02:33<00:00, 2001.94it/s]\n",
      "100%|██████████| 1000/1000 [00:18<00:00, 55.41it/s]\n",
      "100%|██████████| 306492/306492 [02:26<00:00, 2085.69it/s]\n",
      "100%|██████████| 1000/1000 [00:14<00:00, 66.71it/s]\n",
      "100%|██████████| 306492/306492 [02:18<00:00, 2210.46it/s]\n",
      "100%|██████████| 1000/1000 [00:43<00:00, 22.96it/s]\n",
      "100%|██████████| 306492/306492 [03:20<00:00, 1525.57it/s]\n",
      "100%|██████████| 1000/1000 [00:34<00:00, 28.98it/s]\n",
      "100%|██████████| 306492/306492 [03:13<00:00, 1581.81it/s]\n",
      "100%|██████████| 1000/1000 [00:26<00:00, 37.32it/s]\n",
      "100%|██████████| 306492/306492 [03:04<00:00, 1664.57it/s]\n",
      "100%|██████████| 1000/1000 [00:20<00:00, 48.62it/s]\n",
      "100%|██████████| 306492/306492 [02:53<00:00, 1763.44it/s]\n",
      "100%|██████████| 1000/1000 [00:15<00:00, 63.59it/s]\n",
      "100%|██████████| 306492/306492 [02:40<00:00, 1915.20it/s]\n",
      "100%|██████████| 1000/1000 [00:59<00:00, 16.74it/s]\n",
      "100%|██████████| 306492/306492 [03:58<00:00, 1285.48it/s]\n",
      "100%|██████████| 1000/1000 [00:44<00:00, 22.39it/s]\n",
      "100%|██████████| 306492/306492 [03:45<00:00, 1357.94it/s]\n",
      "100%|██████████| 1000/1000 [00:32<00:00, 30.83it/s]\n",
      "100%|██████████| 306492/306492 [03:35<00:00, 1422.26it/s]\n",
      "100%|██████████| 1000/1000 [00:23<00:00, 43.40it/s]\n",
      "100%|██████████| 306492/306492 [03:23<00:00, 1503.73it/s]\n",
      "100%|██████████| 1000/1000 [00:16<00:00, 61.04it/s]\n",
      "100%|██████████| 306492/306492 [03:05<00:00, 1651.38it/s]\n",
      "100%|██████████| 1000/1000 [00:43<00:00, 22.84it/s]\n",
      "100%|██████████| 306492/306492 [03:23<00:00, 1502.78it/s]\n"
     ]
    }
   ],
   "source": [
    "best_params = fit_random_walk(train_g, graph, params = params, k = k )\n",
    "topk_visited_anime, test_hr_dict, test_precision_dict = test_random_walk(valid_g, graph, best_params, max_k = k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e7d4db-c639-4a5f-afc2-2a82c21c6e05",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Why random walk perform better\n",
    "- Simpler approach\n",
    "- Different neighbour will have different importance, rather than assumming they are same \n",
    "- Take information from more than 3 hop neighbour (which is better than 2 hop neighbour)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6465fbe-7ee3-4b60-b247-cf7f21ebef89",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Generate Recommendation\n",
    "- show the result recommendation for some user and what they have watch before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af4026ca-83c5-46ec-8637-b50b96ae0671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ced3c9a-3dbb-4b1d-82f7-9770f617dc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 203.04it/s]\n",
      "100%|██████████| 306492/306492 [04:27<00:00, 1147.48it/s]\n"
     ]
    }
   ],
   "source": [
    "recommended_anime = recommend_with_random_walk(graph.to(device), **best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9e9811b-79a8-46b2-bf88-acc2b4cfa5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_data = pd.read_csv(\"./data/anime.csv\", na_values = \"Unknown\")\n",
    "anime_mapper = torch.load(\"data/anime_id_mapper.pt\")\n",
    "anime_mapper = {v:k for k, v in anime_mapper.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1a83f219-74ae-4e12-9d3d-1ce7f134c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx2anime(anime_data: pd.DataFrame, anime_mapper: dict, recommendation_idx: list) -> pd.DataFrame:\n",
    "    result = pd.DataFrame({\"anime_id\": [anime_mapper[idx] for idx in recommendation_idx]})\n",
    "    result = result.merge(\n",
    "        anime_data,\n",
    "        left_on='anime_id', right_on=\"MAL_ID\"\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "722534c3-a48d-4977-b2bc-d069e5794583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>MAL_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Score</th>\n",
       "      <th>Genres</th>\n",
       "      <th>English name</th>\n",
       "      <th>Japanese name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Episodes</th>\n",
       "      <th>Aired</th>\n",
       "      <th>...</th>\n",
       "      <th>Score-10</th>\n",
       "      <th>Score-9</th>\n",
       "      <th>Score-8</th>\n",
       "      <th>Score-7</th>\n",
       "      <th>Score-6</th>\n",
       "      <th>Score-5</th>\n",
       "      <th>Score-4</th>\n",
       "      <th>Score-3</th>\n",
       "      <th>Score-2</th>\n",
       "      <th>Score-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1575</td>\n",
       "      <td>1575</td>\n",
       "      <td>Code Geass: Hangyaku no Lelouch</td>\n",
       "      <td>8.72</td>\n",
       "      <td>Action, Military, Sci-Fi, Super Power, Drama, ...</td>\n",
       "      <td>Code Geass:Lelouch of the Rebellion</td>\n",
       "      <td>コードギアス 反逆のルルーシュ</td>\n",
       "      <td>TV</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Oct 6, 2006 to Jul 29, 2007</td>\n",
       "      <td>...</td>\n",
       "      <td>326710.0</td>\n",
       "      <td>309688.0</td>\n",
       "      <td>213516.0</td>\n",
       "      <td>93305.0</td>\n",
       "      <td>31697.0</td>\n",
       "      <td>14686.0</td>\n",
       "      <td>7065.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>1630.0</td>\n",
       "      <td>2621.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19815</td>\n",
       "      <td>19815</td>\n",
       "      <td>No Game No Life</td>\n",
       "      <td>8.20</td>\n",
       "      <td>Game, Adventure, Comedy, Supernatural, Ecchi, ...</td>\n",
       "      <td>No Game, No Life</td>\n",
       "      <td>ノーゲーム・ノーライフ</td>\n",
       "      <td>TV</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Apr 9, 2014 to Jun 25, 2014</td>\n",
       "      <td>...</td>\n",
       "      <td>227827.0</td>\n",
       "      <td>285623.0</td>\n",
       "      <td>309230.0</td>\n",
       "      <td>186864.0</td>\n",
       "      <td>70141.0</td>\n",
       "      <td>30284.0</td>\n",
       "      <td>14345.0</td>\n",
       "      <td>6228.0</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>3521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4224</td>\n",
       "      <td>4224</td>\n",
       "      <td>Toradora!</td>\n",
       "      <td>8.24</td>\n",
       "      <td>Slice of Life, Comedy, Romance, School</td>\n",
       "      <td>Toradora!</td>\n",
       "      <td>とらドラ！</td>\n",
       "      <td>TV</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Oct 2, 2008 to Mar 26, 2009</td>\n",
       "      <td>...</td>\n",
       "      <td>185286.0</td>\n",
       "      <td>255249.0</td>\n",
       "      <td>273494.0</td>\n",
       "      <td>160797.0</td>\n",
       "      <td>58749.0</td>\n",
       "      <td>25479.0</td>\n",
       "      <td>10810.0</td>\n",
       "      <td>4372.0</td>\n",
       "      <td>2456.0</td>\n",
       "      <td>2890.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5114</td>\n",
       "      <td>5114</td>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>9.19</td>\n",
       "      <td>Action, Military, Adventure, Comedy, Drama, Ma...</td>\n",
       "      <td>Fullmetal Alchemist:Brotherhood</td>\n",
       "      <td>鋼の錬金術師 FULLMETAL ALCHEMIST</td>\n",
       "      <td>TV</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Apr 5, 2009 to Jul 4, 2010</td>\n",
       "      <td>...</td>\n",
       "      <td>714811.0</td>\n",
       "      <td>401507.0</td>\n",
       "      <td>199160.0</td>\n",
       "      <td>70045.0</td>\n",
       "      <td>20210.0</td>\n",
       "      <td>9308.0</td>\n",
       "      <td>3222.0</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>2162.0</td>\n",
       "      <td>16806.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1535</td>\n",
       "      <td>1535</td>\n",
       "      <td>Death Note</td>\n",
       "      <td>8.63</td>\n",
       "      <td>Mystery, Police, Psychological, Supernatural, ...</td>\n",
       "      <td>Death Note</td>\n",
       "      <td>デスノート</td>\n",
       "      <td>TV</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Oct 4, 2006 to Jun 27, 2007</td>\n",
       "      <td>...</td>\n",
       "      <td>557406.0</td>\n",
       "      <td>535252.0</td>\n",
       "      <td>415890.0</td>\n",
       "      <td>201522.0</td>\n",
       "      <td>68577.0</td>\n",
       "      <td>28048.0</td>\n",
       "      <td>10462.0</td>\n",
       "      <td>3692.0</td>\n",
       "      <td>2256.0</td>\n",
       "      <td>3586.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2904</td>\n",
       "      <td>2904</td>\n",
       "      <td>Code Geass: Hangyaku no Lelouch R2</td>\n",
       "      <td>8.91</td>\n",
       "      <td>Action, Military, Sci-Fi, Super Power, Drama, ...</td>\n",
       "      <td>Code Geass:Lelouch of the Rebellion R2</td>\n",
       "      <td>コードギアス 反逆のルルーシュ 続編</td>\n",
       "      <td>TV</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Apr 6, 2008 to Sep 28, 2008</td>\n",
       "      <td>...</td>\n",
       "      <td>358705.0</td>\n",
       "      <td>247100.0</td>\n",
       "      <td>148191.0</td>\n",
       "      <td>65065.0</td>\n",
       "      <td>22685.0</td>\n",
       "      <td>9786.0</td>\n",
       "      <td>5306.0</td>\n",
       "      <td>2505.0</td>\n",
       "      <td>1322.0</td>\n",
       "      <td>2250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16498</td>\n",
       "      <td>16498</td>\n",
       "      <td>Shingeki no Kyojin</td>\n",
       "      <td>8.48</td>\n",
       "      <td>Action, Military, Mystery, Super Power, Drama,...</td>\n",
       "      <td>Attack on Titan</td>\n",
       "      <td>進撃の巨人</td>\n",
       "      <td>TV</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Apr 7, 2013 to Sep 29, 2013</td>\n",
       "      <td>...</td>\n",
       "      <td>470882.0</td>\n",
       "      <td>514879.0</td>\n",
       "      <td>459113.0</td>\n",
       "      <td>220228.0</td>\n",
       "      <td>70768.0</td>\n",
       "      <td>31141.0</td>\n",
       "      <td>11805.0</td>\n",
       "      <td>4637.0</td>\n",
       "      <td>2707.0</td>\n",
       "      <td>4939.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23273</td>\n",
       "      <td>23273</td>\n",
       "      <td>Shigatsu wa Kimi no Uso</td>\n",
       "      <td>8.74</td>\n",
       "      <td>Drama, Music, Romance, School, Shounen</td>\n",
       "      <td>Your Lie in April</td>\n",
       "      <td>四月は君の嘘</td>\n",
       "      <td>TV</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Oct 10, 2014 to Mar 20, 2015</td>\n",
       "      <td>...</td>\n",
       "      <td>307670.0</td>\n",
       "      <td>250337.0</td>\n",
       "      <td>177967.0</td>\n",
       "      <td>82986.0</td>\n",
       "      <td>30877.0</td>\n",
       "      <td>14233.0</td>\n",
       "      <td>7001.0</td>\n",
       "      <td>2911.0</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>2645.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33486</td>\n",
       "      <td>33486</td>\n",
       "      <td>Boku no Hero Academia 2nd Season</td>\n",
       "      <td>8.33</td>\n",
       "      <td>Action, Comedy, Super Power, School, Shounen</td>\n",
       "      <td>My Hero Academia 2</td>\n",
       "      <td>僕のヒーローアカデミア</td>\n",
       "      <td>TV</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Apr 1, 2017 to Sep 30, 2017</td>\n",
       "      <td>...</td>\n",
       "      <td>188165.0</td>\n",
       "      <td>322936.0</td>\n",
       "      <td>347893.0</td>\n",
       "      <td>166839.0</td>\n",
       "      <td>46700.0</td>\n",
       "      <td>16556.0</td>\n",
       "      <td>4760.0</td>\n",
       "      <td>1849.0</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25777</td>\n",
       "      <td>25777</td>\n",
       "      <td>Shingeki no Kyojin Season 2</td>\n",
       "      <td>8.45</td>\n",
       "      <td>Action, Military, Mystery, Super Power, Drama,...</td>\n",
       "      <td>Attack on Titan Season 2</td>\n",
       "      <td>進撃の巨人 Season2</td>\n",
       "      <td>TV</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Apr 1, 2017 to Jun 17, 2017</td>\n",
       "      <td>...</td>\n",
       "      <td>239823.0</td>\n",
       "      <td>308956.0</td>\n",
       "      <td>304020.0</td>\n",
       "      <td>135241.0</td>\n",
       "      <td>38504.0</td>\n",
       "      <td>12841.0</td>\n",
       "      <td>5160.0</td>\n",
       "      <td>1716.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>1804.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   anime_id  MAL_ID                                Name  Score  \\\n",
       "4      1575    1575     Code Geass: Hangyaku no Lelouch   8.72   \n",
       "0     19815   19815                     No Game No Life   8.20   \n",
       "8      4224    4224                           Toradora!   8.24   \n",
       "3      5114    5114    Fullmetal Alchemist: Brotherhood   9.19   \n",
       "1      1535    1535                          Death Note   8.63   \n",
       "2      2904    2904  Code Geass: Hangyaku no Lelouch R2   8.91   \n",
       "6     16498   16498                  Shingeki no Kyojin   8.48   \n",
       "5     23273   23273             Shigatsu wa Kimi no Uso   8.74   \n",
       "7     33486   33486    Boku no Hero Academia 2nd Season   8.33   \n",
       "9     25777   25777         Shingeki no Kyojin Season 2   8.45   \n",
       "\n",
       "                                              Genres  \\\n",
       "4  Action, Military, Sci-Fi, Super Power, Drama, ...   \n",
       "0  Game, Adventure, Comedy, Supernatural, Ecchi, ...   \n",
       "8             Slice of Life, Comedy, Romance, School   \n",
       "3  Action, Military, Adventure, Comedy, Drama, Ma...   \n",
       "1  Mystery, Police, Psychological, Supernatural, ...   \n",
       "2  Action, Military, Sci-Fi, Super Power, Drama, ...   \n",
       "6  Action, Military, Mystery, Super Power, Drama,...   \n",
       "5             Drama, Music, Romance, School, Shounen   \n",
       "7       Action, Comedy, Super Power, School, Shounen   \n",
       "9  Action, Military, Mystery, Super Power, Drama,...   \n",
       "\n",
       "                             English name               Japanese name Type  \\\n",
       "4     Code Geass:Lelouch of the Rebellion             コードギアス 反逆のルルーシュ   TV   \n",
       "0                        No Game, No Life                 ノーゲーム・ノーライフ   TV   \n",
       "8                               Toradora!                       とらドラ！   TV   \n",
       "3         Fullmetal Alchemist:Brotherhood  鋼の錬金術師 FULLMETAL ALCHEMIST   TV   \n",
       "1                              Death Note                       デスノート   TV   \n",
       "2  Code Geass:Lelouch of the Rebellion R2          コードギアス 反逆のルルーシュ 続編   TV   \n",
       "6                         Attack on Titan                       進撃の巨人   TV   \n",
       "5                       Your Lie in April                      四月は君の嘘   TV   \n",
       "7                      My Hero Academia 2                 僕のヒーローアカデミア   TV   \n",
       "9                Attack on Titan Season 2               進撃の巨人 Season2   TV   \n",
       "\n",
       "   Episodes                         Aired  ...  Score-10   Score-9   Score-8  \\\n",
       "4      25.0   Oct 6, 2006 to Jul 29, 2007  ...  326710.0  309688.0  213516.0   \n",
       "0      12.0   Apr 9, 2014 to Jun 25, 2014  ...  227827.0  285623.0  309230.0   \n",
       "8      25.0   Oct 2, 2008 to Mar 26, 2009  ...  185286.0  255249.0  273494.0   \n",
       "3      64.0    Apr 5, 2009 to Jul 4, 2010  ...  714811.0  401507.0  199160.0   \n",
       "1      37.0   Oct 4, 2006 to Jun 27, 2007  ...  557406.0  535252.0  415890.0   \n",
       "2      25.0   Apr 6, 2008 to Sep 28, 2008  ...  358705.0  247100.0  148191.0   \n",
       "6      25.0   Apr 7, 2013 to Sep 29, 2013  ...  470882.0  514879.0  459113.0   \n",
       "5      22.0  Oct 10, 2014 to Mar 20, 2015  ...  307670.0  250337.0  177967.0   \n",
       "7      25.0   Apr 1, 2017 to Sep 30, 2017  ...  188165.0  322936.0  347893.0   \n",
       "9      12.0   Apr 1, 2017 to Jun 17, 2017  ...  239823.0  308956.0  304020.0   \n",
       "\n",
       "    Score-7  Score-6  Score-5  Score-4  Score-3  Score-2  Score-1  \n",
       "4   93305.0  31697.0  14686.0   7065.0   3100.0   1630.0   2621.0  \n",
       "0  186864.0  70141.0  30284.0  14345.0   6228.0   3313.0   3521.0  \n",
       "8  160797.0  58749.0  25479.0  10810.0   4372.0   2456.0   2890.0  \n",
       "3   70045.0  20210.0   9308.0   3222.0   1536.0   2162.0  16806.0  \n",
       "1  201522.0  68577.0  28048.0  10462.0   3692.0   2256.0   3586.0  \n",
       "2   65065.0  22685.0   9786.0   5306.0   2505.0   1322.0   2250.0  \n",
       "6  220228.0  70768.0  31141.0  11805.0   4637.0   2707.0   4939.0  \n",
       "5   82986.0  30877.0  14233.0   7001.0   2911.0   1562.0   2645.0  \n",
       "7  166839.0  46700.0  16556.0   4760.0   1849.0    948.0   2065.0  \n",
       "9  135241.0  38504.0  12841.0   5160.0   1716.0    839.0   1804.0  \n",
       "\n",
       "[10 rows x 36 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_user_idx = np.random.randint(0, graph.num_nodes(\"user\"))\n",
    "recommendation_df = idx2anime(anime_data, anime_mapper, recommended_anime[random_user_idx])\n",
    "recommendation_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f5c6fb09-28f2-489c-ac98-5ba3bd056811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>MAL_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Score</th>\n",
       "      <th>Genres</th>\n",
       "      <th>English name</th>\n",
       "      <th>Japanese name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Episodes</th>\n",
       "      <th>Aired</th>\n",
       "      <th>...</th>\n",
       "      <th>Score-10</th>\n",
       "      <th>Score-9</th>\n",
       "      <th>Score-8</th>\n",
       "      <th>Score-7</th>\n",
       "      <th>Score-6</th>\n",
       "      <th>Score-5</th>\n",
       "      <th>Score-4</th>\n",
       "      <th>Score-3</th>\n",
       "      <th>Score-2</th>\n",
       "      <th>Score-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>11577</td>\n",
       "      <td>11577</td>\n",
       "      <td>Steins;Gate Movie: Fuka Ryouiki no Déjà vu</td>\n",
       "      <td>8.50</td>\n",
       "      <td>Sci-Fi, Drama</td>\n",
       "      <td>Steins;Gate:The Movie − Load Region of Déjà Vu</td>\n",
       "      <td>劇場版 シュタインズゲート 負荷領域のデジャヴ</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Apr 20, 2013</td>\n",
       "      <td>...</td>\n",
       "      <td>63370.0</td>\n",
       "      <td>83098.0</td>\n",
       "      <td>69984.0</td>\n",
       "      <td>32171.0</td>\n",
       "      <td>10369.0</td>\n",
       "      <td>3911.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>628.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>690.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6547</td>\n",
       "      <td>6547</td>\n",
       "      <td>Angel Beats!</td>\n",
       "      <td>8.15</td>\n",
       "      <td>Action, Comedy, Drama, School, Supernatural</td>\n",
       "      <td>Angel Beats!</td>\n",
       "      <td>Angel Beats!（エンジェルビーツ）</td>\n",
       "      <td>TV</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Apr 3, 2010 to Jun 26, 2010</td>\n",
       "      <td>...</td>\n",
       "      <td>200757.0</td>\n",
       "      <td>242398.0</td>\n",
       "      <td>264330.0</td>\n",
       "      <td>169476.0</td>\n",
       "      <td>68296.0</td>\n",
       "      <td>31152.0</td>\n",
       "      <td>14127.0</td>\n",
       "      <td>5810.0</td>\n",
       "      <td>2758.0</td>\n",
       "      <td>2569.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20517</td>\n",
       "      <td>20517</td>\n",
       "      <td>Little Busters!: EX</td>\n",
       "      <td>7.74</td>\n",
       "      <td>Slice of Life, Comedy, Supernatural, Drama, Ro...</td>\n",
       "      <td>Little Busters! EX</td>\n",
       "      <td>リトルバスターズ！EX</td>\n",
       "      <td>Special</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Jan 29, 2014 to Jul 30, 2014</td>\n",
       "      <td>...</td>\n",
       "      <td>2493.0</td>\n",
       "      <td>3678.0</td>\n",
       "      <td>6886.0</td>\n",
       "      <td>5233.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>818.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>27775</td>\n",
       "      <td>27775</td>\n",
       "      <td>Plastic Memories</td>\n",
       "      <td>7.94</td>\n",
       "      <td>Sci-Fi, Drama, Romance</td>\n",
       "      <td>Plastic Memories</td>\n",
       "      <td>プラスティック・メモリーズ</td>\n",
       "      <td>TV</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Apr 5, 2015 to Jun 28, 2015</td>\n",
       "      <td>...</td>\n",
       "      <td>51548.0</td>\n",
       "      <td>66207.0</td>\n",
       "      <td>94793.0</td>\n",
       "      <td>65999.0</td>\n",
       "      <td>26175.0</td>\n",
       "      <td>11927.0</td>\n",
       "      <td>5412.0</td>\n",
       "      <td>2090.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>739.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28851</td>\n",
       "      <td>28851</td>\n",
       "      <td>Koe no Katachi</td>\n",
       "      <td>9.00</td>\n",
       "      <td>Drama, School, Shounen</td>\n",
       "      <td>A Silent Voice</td>\n",
       "      <td>聲の形</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sep 17, 2016</td>\n",
       "      <td>...</td>\n",
       "      <td>393684.0</td>\n",
       "      <td>295492.0</td>\n",
       "      <td>156604.0</td>\n",
       "      <td>61581.0</td>\n",
       "      <td>19228.0</td>\n",
       "      <td>7135.0</td>\n",
       "      <td>3108.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>698.0</td>\n",
       "      <td>2071.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33731</td>\n",
       "      <td>33731</td>\n",
       "      <td>Gabriel DropOut</td>\n",
       "      <td>7.49</td>\n",
       "      <td>Comedy, Demons, Supernatural, School, Shounen</td>\n",
       "      <td>Gabriel DropOut</td>\n",
       "      <td>ガヴリールドロップアウト</td>\n",
       "      <td>TV</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Jan 9, 2017 to Mar 27, 2017</td>\n",
       "      <td>...</td>\n",
       "      <td>12557.0</td>\n",
       "      <td>22652.0</td>\n",
       "      <td>55211.0</td>\n",
       "      <td>55489.0</td>\n",
       "      <td>21305.0</td>\n",
       "      <td>8645.0</td>\n",
       "      <td>2852.0</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20517</td>\n",
       "      <td>20517</td>\n",
       "      <td>Little Busters!: EX</td>\n",
       "      <td>7.74</td>\n",
       "      <td>Slice of Life, Comedy, Supernatural, Drama, Ro...</td>\n",
       "      <td>Little Busters! EX</td>\n",
       "      <td>リトルバスターズ！EX</td>\n",
       "      <td>Special</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Jan 29, 2014 to Jul 30, 2014</td>\n",
       "      <td>...</td>\n",
       "      <td>2493.0</td>\n",
       "      <td>3678.0</td>\n",
       "      <td>6886.0</td>\n",
       "      <td>5233.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>818.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13125</td>\n",
       "      <td>13125</td>\n",
       "      <td>Shinsekai yori</td>\n",
       "      <td>8.35</td>\n",
       "      <td>Drama, Horror, Mystery, Psychological, Sci-Fi,...</td>\n",
       "      <td>From the New World</td>\n",
       "      <td>新世界より</td>\n",
       "      <td>TV</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Sep 29, 2012 to Mar 23, 2013</td>\n",
       "      <td>...</td>\n",
       "      <td>56953.0</td>\n",
       "      <td>64171.0</td>\n",
       "      <td>53956.0</td>\n",
       "      <td>29407.0</td>\n",
       "      <td>12975.0</td>\n",
       "      <td>6878.0</td>\n",
       "      <td>3978.0</td>\n",
       "      <td>1772.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>32281</td>\n",
       "      <td>32281</td>\n",
       "      <td>Kimi no Na wa.</td>\n",
       "      <td>8.96</td>\n",
       "      <td>Romance, Supernatural, School, Drama</td>\n",
       "      <td>Your Name.</td>\n",
       "      <td>君の名は。</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Aug 26, 2016</td>\n",
       "      <td>...</td>\n",
       "      <td>516874.0</td>\n",
       "      <td>333022.0</td>\n",
       "      <td>200239.0</td>\n",
       "      <td>86314.0</td>\n",
       "      <td>29641.0</td>\n",
       "      <td>12257.0</td>\n",
       "      <td>5199.0</td>\n",
       "      <td>2131.0</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>3966.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18195</td>\n",
       "      <td>18195</td>\n",
       "      <td>Little Busters!: Refrain</td>\n",
       "      <td>8.23</td>\n",
       "      <td>Slice of Life, Comedy, Supernatural, Drama, Ro...</td>\n",
       "      <td>Little Busters! ~Refrain~</td>\n",
       "      <td>リトルバスターズ！～Refrain～</td>\n",
       "      <td>TV</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Oct 5, 2013 to Dec 28, 2013</td>\n",
       "      <td>...</td>\n",
       "      <td>13328.0</td>\n",
       "      <td>16946.0</td>\n",
       "      <td>17388.0</td>\n",
       "      <td>10182.0</td>\n",
       "      <td>4043.0</td>\n",
       "      <td>1767.0</td>\n",
       "      <td>773.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>171.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    anime_id  MAL_ID                                        Name  Score  \\\n",
       "35     11577   11577  Steins;Gate Movie: Fuka Ryouiki no Déjà vu   8.50   \n",
       "25      6547    6547                                Angel Beats!   8.15   \n",
       "32     20517   20517                         Little Busters!: EX   7.74   \n",
       "29     27775   27775                            Plastic Memories   7.94   \n",
       "0      28851   28851                              Koe no Katachi   9.00   \n",
       "6      33731   33731                             Gabriel DropOut   7.49   \n",
       "32     20517   20517                         Little Busters!: EX   7.74   \n",
       "28     13125   13125                              Shinsekai yori   8.35   \n",
       "26     32281   32281                              Kimi no Na wa.   8.96   \n",
       "13     18195   18195                    Little Busters!: Refrain   8.23   \n",
       "\n",
       "                                               Genres  \\\n",
       "35                                      Sci-Fi, Drama   \n",
       "25        Action, Comedy, Drama, School, Supernatural   \n",
       "32  Slice of Life, Comedy, Supernatural, Drama, Ro...   \n",
       "29                             Sci-Fi, Drama, Romance   \n",
       "0                              Drama, School, Shounen   \n",
       "6       Comedy, Demons, Supernatural, School, Shounen   \n",
       "32  Slice of Life, Comedy, Supernatural, Drama, Ro...   \n",
       "28  Drama, Horror, Mystery, Psychological, Sci-Fi,...   \n",
       "26               Romance, Supernatural, School, Drama   \n",
       "13  Slice of Life, Comedy, Supernatural, Drama, Ro...   \n",
       "\n",
       "                                      English name            Japanese name  \\\n",
       "35  Steins;Gate:The Movie − Load Region of Déjà Vu  劇場版 シュタインズゲート 負荷領域のデジャヴ   \n",
       "25                                    Angel Beats!   Angel Beats!（エンジェルビーツ）   \n",
       "32                              Little Busters! EX              リトルバスターズ！EX   \n",
       "29                                Plastic Memories            プラスティック・メモリーズ   \n",
       "0                                   A Silent Voice                      聲の形   \n",
       "6                                  Gabriel DropOut             ガヴリールドロップアウト   \n",
       "32                              Little Busters! EX              リトルバスターズ！EX   \n",
       "28                              From the New World                    新世界より   \n",
       "26                                      Your Name.                    君の名は。   \n",
       "13                       Little Busters! ~Refrain~       リトルバスターズ！～Refrain～   \n",
       "\n",
       "       Type  Episodes                         Aired  ...  Score-10   Score-9  \\\n",
       "35    Movie       1.0                  Apr 20, 2013  ...   63370.0   83098.0   \n",
       "25       TV      13.0   Apr 3, 2010 to Jun 26, 2010  ...  200757.0  242398.0   \n",
       "32  Special       8.0  Jan 29, 2014 to Jul 30, 2014  ...    2493.0    3678.0   \n",
       "29       TV      13.0   Apr 5, 2015 to Jun 28, 2015  ...   51548.0   66207.0   \n",
       "0     Movie       1.0                  Sep 17, 2016  ...  393684.0  295492.0   \n",
       "6        TV      12.0   Jan 9, 2017 to Mar 27, 2017  ...   12557.0   22652.0   \n",
       "32  Special       8.0  Jan 29, 2014 to Jul 30, 2014  ...    2493.0    3678.0   \n",
       "28       TV      25.0  Sep 29, 2012 to Mar 23, 2013  ...   56953.0   64171.0   \n",
       "26    Movie       1.0                  Aug 26, 2016  ...  516874.0  333022.0   \n",
       "13       TV      13.0   Oct 5, 2013 to Dec 28, 2013  ...   13328.0   16946.0   \n",
       "\n",
       "     Score-8   Score-7  Score-6  Score-5  Score-4  Score-3  Score-2  Score-1  \n",
       "35   69984.0   32171.0  10369.0   3911.0   1604.0    628.0    310.0    690.0  \n",
       "25  264330.0  169476.0  68296.0  31152.0  14127.0   5810.0   2758.0   2569.0  \n",
       "32    6886.0    5233.0   1963.0    818.0    293.0    113.0     53.0     60.0  \n",
       "29   94793.0   65999.0  26175.0  11927.0   5412.0   2090.0    945.0    739.0  \n",
       "0   156604.0   61581.0  19228.0   7135.0   3108.0   1242.0    698.0   2071.0  \n",
       "6    55211.0   55489.0  21305.0   8645.0   2852.0   1055.0    462.0    400.0  \n",
       "32    6886.0    5233.0   1963.0    818.0    293.0    113.0     53.0     60.0  \n",
       "28   53956.0   29407.0  12975.0   6878.0   3978.0   1772.0   1021.0   1257.0  \n",
       "26  200239.0   86314.0  29641.0  12257.0   5199.0   2131.0   1116.0   3966.0  \n",
       "13   17388.0   10182.0   4043.0   1767.0    773.0    298.0    155.0    171.0  \n",
       "\n",
       "[10 rows x 36 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, v = graph.out_edges([random_user_idx], etype='like')\n",
    "watched_df = idx2anime(anime_data, anime_mapper, v.tolist())\n",
    "watched_df.sample(10, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca46db8-8189-419d-bcd4-6f6ce0fcf150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6a0123-732d-4465-a37f-b3aa57d61542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv:Python",
   "language": "python",
   "name": "conda-env-venv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
