{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Aws Redshift cluster (IaC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 \n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import json \n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open(\"cluster.ini\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = config.get(\"AWS\", \"KEY\")\n",
    "SECRET = config.get(\"AWS\", \"SECRET\")\n",
    "DWH_CLUSTE_TYPE = config.get(\"DWH\", \"DWH_CLUSTE_TYPE\")\n",
    "DWH_NUM_NODES = config.get(\"DWH\", \"DWH_NUM_NODES\")\n",
    "DWH_NODE_TYPE = config.get(\"DWH\", \"DWH_NODE_TYPE\")\n",
    "DWH_CLUSTER_IDENIFIER = config.get(\"DWH\", \"DWH_CLUSTER_IDENIFIER\")\n",
    "DWH_DB = config.get(\"DWH\", \"DWH_DB\")\n",
    "DWH_DB_USER = config.get(\"DWH\", \"DWH_DB_USER\")\n",
    "DWH_DB_PASSWORD = config.get(\"DWH\", \"DWH_DB_PASSWORD\")\n",
    "DWH_PORT = config.get(\"DWH\", \"DWH_PORT\")\n",
    "DWH_IAM_ROLE_NAME = config.get(\"DWH\", \"DWH_IAM_ROLE_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interact with different service in aws \n",
    "ec2 = boto3.resource(\n",
    "    'ec2',\n",
    "    region_name=\"ap-east-1\",\n",
    "    aws_access_key_id=KEY,\n",
    "    aws_secret_access_key=SECRET\n",
    ")\n",
    "\n",
    "s3 = boto3.resource(\n",
    "    's3',\n",
    "    region_name=\"ap-east-1\",\n",
    "    aws_access_key_id=KEY,\n",
    "    aws_secret_access_key=SECRET\n",
    ")\n",
    "\n",
    "iam = boto3.client(\n",
    "    'iam',\n",
    "    region_name=\"ap-east-1\",\n",
    "    aws_access_key_id=KEY,\n",
    "    aws_secret_access_key=SECRET\n",
    ")\n",
    "\n",
    "redshift = boto3.client(\n",
    "    'redshift',\n",
    "    region_name=\"ap-east-1\",\n",
    "    aws_access_key_id=KEY,\n",
    "    aws_secret_access_key=SECRET\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tickitdb/allevents_pipe.txt',\n",
       " 'tickitdb/allusers_pipe.txt',\n",
       " 'tickitdb/category_pipe.txt',\n",
       " 'tickitdb/date2008_pipe.txt',\n",
       " 'tickitdb/listings_pipe.txt',\n",
       " 'tickitdb/sales_tab.txt',\n",
       " 'tickitdb/venue_pipe.txt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log the practice data from tickitdb folder in the bucket\n",
    "bucket=s3.Bucket(\"redshift-practice-thlawab\")\n",
    "log_data_files=[filename.key for filename in bucket.objects.filter(Prefix='tickitdb/')]\n",
    "log_data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifier for iam roles \n",
    "roleArn = iam.get_role(RoleName=DWH_IAM_ROLE_NAME)[\"Role\"][\"Arn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create redshift cluster with code  \n",
    "try:\n",
    "    response = redshift.create_cluster(\n",
    "        ClusterType=DWH_CLUSTE_TYPE,\n",
    "        NodeType=DWH_NODE_TYPE,\n",
    "        # Credentials & Identifiers\n",
    "        DBName=DWH_DB,\n",
    "        ClusterIdentifier=DWH_CLUSTER_IDENIFIER,\n",
    "        MasterUsername=DWH_DB_USER,\n",
    "        MasterUserPassword=DWH_DB_PASSWORD,\n",
    "        # Role for s3 access \n",
    "        IamRoles=[roleArn]\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the redshift cluster info\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENIFIER)[\"Clusters\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DWH_ENDPOINT = myClusterProps['Endpoint']['Address']\n",
    "DWH_ROLE_ARN = myClusterProps['IamRoles'][0]['IamRoleArn']\n",
    "DWH_VPC = myClusterProps['VpcId']\n",
    "DB_NAME = myClusterProps['DBName']\n",
    "DB_USER = myClusterProps['MasterUsername']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2.SecurityGroup(id='sg-0112e8b0cf043dd33')\n"
     ]
    }
   ],
   "source": [
    "# Configure security group (inbound role) for redshift cluster \n",
    "try:\n",
    "    vpc = ec2.Vpc(id=DWH_VPC)\n",
    "    defaultSg = list(vpc.security_groups.all())[0]\n",
    "    print(defaultSg)\n",
    "    defaultSg.authorize_ingress(\n",
    "        GroupName=defaultSg.group_name,\n",
    "        CidrIp='0.0.0.0/0',\n",
    "        IpProtocol='TCP',\n",
    "        FromPort=int(DWH_PORT),\n",
    "        ToPort=int(DWH_PORT)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect Aws Redshift Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=DWH_ENDPOINT,\n",
    "        dbname=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DWH_DB_PASSWORD,\n",
    "        port=DWH_PORT\n",
    "    )\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Could not make connection to the aws redshift\")\n",
    "    print(e)\n",
    "\n",
    "conn.set_session(autocommit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur = conn.cursor()\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Could not get cursor to the Database\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Table for the data model\n",
    "try:\n",
    "    cur.execute(\n",
    "    \"\"\"\n",
    "    create table IF NOT EXISTS users(\n",
    "        userid integer not null distkey sortkey,\n",
    "        username char(8),\n",
    "        firstname char(30),\n",
    "        lastname char(30),\n",
    "        city varchar(30),\n",
    "        state char(2),\n",
    "        email varchar(100),\n",
    "        phone char(14),\n",
    "        likesports boolean,\n",
    "        liketheatre boolean,\n",
    "        likeconcerts boolean,\n",
    "        likejazz boolean,\n",
    "        likeclassical boolean,\n",
    "        likeopera boolean,\n",
    "        likerock boolean,\n",
    "        likevegas boolean,\n",
    "        likebroadway boolean,\n",
    "        likemusicals boolean\n",
    "    );\n",
    "\n",
    "    create table IF NOT EXISTS venue(\n",
    "        venueid smallint not null distkey sortkey,\n",
    "        venuename varchar(100),\n",
    "        venuecity varchar(30),\n",
    "        venuestate char(2),\n",
    "        venueseats integer\n",
    "    );\n",
    "\n",
    "    create table IF NOT EXISTS category(\n",
    "        catid smallint not null distkey sortkey,\n",
    "        catgroup varchar(10),\n",
    "        catname varchar(10),\n",
    "        catdesc varchar(50)\n",
    "    );\n",
    "\n",
    "    create table IF NOT EXISTS date(\n",
    "        dateid smallint not null distkey sortkey,\n",
    "        caldate date not null,\n",
    "        day char(3) not null,\n",
    "        week smallint not null,\n",
    "        month char(5) not null,\n",
    "        qtr char(5) not null,\n",
    "        year smallint not null,\n",
    "        hoilday boolean default('N')\n",
    "    );\n",
    "\n",
    "    create table IF NOT EXISTS event(\n",
    "        eventid integer not null distkey,\n",
    "        venueid smallint not null,\n",
    "        catid smallint not null,\n",
    "        dateid smallint not null sortkey,\n",
    "        eventname varchar(200),\n",
    "        starttime timestamp\n",
    "    );\n",
    "\n",
    "    create table IF NOT EXISTS listing(\n",
    "        listid integer not null distkey,\n",
    "        sellerid integer not null,\n",
    "        eventid integer not null,\n",
    "        dateid smallint not null sortkey,\n",
    "        numtickets smallint not null,\n",
    "        priceperticket decimal(8, 2),\n",
    "        totalprice decimal(8, 2),\n",
    "        listtime timestamp\n",
    "    );\n",
    "\n",
    "    \"\"\"\n",
    "    )\n",
    "except psycopg2.Error as e:\n",
    "    # Roll back the transaction\n",
    "    conn.rollback()\n",
    "    print(\"Error: Issue creating table\")\n",
    "    print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy data from s3 bucket \n",
    "try:\n",
    "    cur.execute(f\"\"\"\n",
    "    copy users from 's3://redshift-practice-thlawab/tickitdb/allusers_pipe.txt'\n",
    "    credentials 'aws_iam_role={DWH_ROLE_ARN}'\n",
    "    delimiter '|'\n",
    "    region 'ap-east-1';\n",
    "\n",
    "    copy venue from 's3://redshift-practice-thlawab/tickitdb/venue_pipe.txt'\n",
    "    credentials 'aws_iam_role={DWH_ROLE_ARN}'\n",
    "    delimiter '|'\n",
    "    region 'ap-east-1';\n",
    "\n",
    "    copy category from 's3://redshift-practice-thlawab/tickitdb/category_pipe.txt'\n",
    "    credentials 'aws_iam_role={DWH_ROLE_ARN}'\n",
    "    delimiter '|'\n",
    "    region 'ap-east-1';\n",
    "\n",
    "    copy date from 's3://redshift-practice-thlawab/tickitdb/date2008_pipe.txt'\n",
    "    credentials 'aws_iam_role={DWH_ROLE_ARN}'\n",
    "    delimiter '|'\n",
    "    region 'ap-east-1';\n",
    "\n",
    "    copy event from 's3://redshift-practice-thlawab/tickitdb/allevents_pipe.txt'\n",
    "    credentials 'aws_iam_role={DWH_ROLE_ARN}'\n",
    "    delimiter '|'\n",
    "    region 'ap-east-1';\n",
    "\n",
    "    copy listing from 's3://redshift-practice-thlawab/tickitdb/listings_pipe.txt'\n",
    "    credentials 'aws_iam_role={DWH_ROLE_ARN}'\n",
    "    delimiter '|'\n",
    "    region 'ap-east-1';\n",
    "    \"\"\")\n",
    "except psycopg2.Error as e:\n",
    "    # Roll back the transaction\n",
    "    conn.rollback()\n",
    "    print(\"Error: Issue copying data to table\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\"\"\"\n",
    "    SELECT * \n",
    "    FROM users \n",
    "    LIMIT 5\n",
    "    ;\n",
    "    \"\"\")\n",
    "except psycopg2.Error as e:\n",
    "    # Roll back the transaction\n",
    "    conn.rollback()\n",
    "    print(\"Error: Issue reading table\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'JSG99FHE', 'Rafael                        ', 'Taylor                        ', 'Kent', 'WA', 'Etiam.laoreet.libero@sodalesMaurisblandit.edu', '(664) 602-4412', True, True, None, False, True, None, None, True, False, True)\n",
      "(3, 'IFT66TXU', 'Lars                          ', 'Ratliff                       ', 'High Point', 'ME', 'amet.faucibus.ut@condimentumegetvolutpat.ca', '(624) 767-2465', True, False, None, False, None, False, True, None, None, True)\n",
      "(6, 'NDQ15VBM', 'Victor                        ', 'Hernandez                     ', 'Naperville', 'GA', 'turpis@accumsanlaoreet.org', '(818) 765-4255', False, None, None, True, None, True, True, True, True, True)\n",
      "(8, 'AZG78YIP', 'Colton                        ', 'Roy                           ', 'Guayama', 'AK', 'ullamcorper.nisl@Cras.edu', '(998) 934-9210', None, None, True, True, None, True, False, None, False, False)\n",
      "(11, 'MFN29TYU', 'Anika                         ', 'Huff                          ', 'Rawlins', 'MT', 'arcu.Curabitur@senectusetnetus.com', '(419) 147-8207', None, None, None, True, None, True, None, None, None, None)\n"
     ]
    }
   ],
   "source": [
    "results = cur.fetchall()\n",
    "for row in results:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn.close()\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClusterNotFoundFault",
     "evalue": "An error occurred (ClusterNotFound) when calling the DeleteCluster operation: Cluster redshift-practice not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mClusterNotFoundFault\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m redshift\u001b[39m.\u001b[39;49mdelete_cluster(\n\u001b[0;32m      2\u001b[0m     ClusterIdentifier\u001b[39m=\u001b[39;49mDWH_CLUSTER_IDENIFIER,\n\u001b[0;32m      3\u001b[0m     SkipFinalClusterSnapshot\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\Documents\\Python-Scripts\\data-projects\\.venv\\lib\\site-packages\\botocore\\client.py:530\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    526\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    527\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpy_operation_name\u001b[39m}\u001b[39;00m\u001b[39m() only accepts keyword arguments.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     )\n\u001b[0;32m    529\u001b[0m \u001b[39m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[1;32m--> 530\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_api_call(operation_name, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\Documents\\Python-Scripts\\data-projects\\.venv\\lib\\site-packages\\botocore\\client.py:964\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[1;34m(self, operation_name, api_params)\u001b[0m\n\u001b[0;32m    962\u001b[0m     error_code \u001b[39m=\u001b[39m parsed_response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mError\u001b[39m\u001b[39m\"\u001b[39m, {})\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mCode\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    963\u001b[0m     error_class \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mfrom_code(error_code)\n\u001b[1;32m--> 964\u001b[0m     \u001b[39mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[0;32m    965\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    966\u001b[0m     \u001b[39mreturn\u001b[39;00m parsed_response\n",
      "\u001b[1;31mClusterNotFoundFault\u001b[0m: An error occurred (ClusterNotFound) when calling the DeleteCluster operation: Cluster redshift-practice not found."
     ]
    }
   ],
   "source": [
    "redshift.delete_cluster(\n",
    "    ClusterIdentifier=DWH_CLUSTER_IDENIFIER,\n",
    "    SkipFinalClusterSnapshot=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
